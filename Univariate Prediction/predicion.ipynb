{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.metrics import mape, mse, mae\n",
    "from darts.models import NaiveMean, NaiveSeasonal, NaiveDrift, NaiveMovingAverage, RandomForest, LinearRegressionModel, AutoARIMA, Theta, StatsForecastAutoETS, Prophet, NBEATSModel, NLinearModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset as a series and prepare it by splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/Custom/H_test_noise.csv\")\n",
    "series = TimeSeries.from_dataframe(df, \"Date\")\n",
    "train, test = series.split_after(0.75)\n",
    "train.plot()\n",
    "test.plot()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"final_dataset.csv\")\n",
    "series_w = TimeSeries.from_dataframe(df, \"Date\")\n",
    "train_w, test_w = series_w.split_after(0.75)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Models - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = NaiveMean()\n",
    "model1 = NaiveSeasonal(K = 24)\n",
    "model2 = NaiveDrift()\n",
    "model3 = NaiveMovingAverage(input_chunk_length = 24)\n",
    "\n",
    "models = {\n",
    "    \"Mean\": model0,\n",
    "    \"Seasonal\": model1,\n",
    "    \"Drift\": model2,\n",
    "    \"MA\": model3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (name, model) in tqdm(enumerate(models.items()), desc=\"Progress\"):\n",
    "  print(name)\n",
    "  model.fit(series=train)\n",
    "  predictions = model.predict(n = len(test))\n",
    "  mae_score = round(mae(test, predictions), 2)\n",
    "  mse_score = round(mse(test, predictions), 2)\n",
    "\n",
    "  fig.add_subplot(2, 2, i+1)\n",
    "  train.plot(label=\"train\"); test.plot(label=\"test\"); predictions.plot(label=name)\n",
    "  plt.title(f\"Method: {name}, MAE: {mae_score}, MSE: {mse_score} with sample selection\"); plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Theta()\n",
    "model1 = LinearRegressionModel(lags=24)\n",
    "model2 = StatsForecastAutoETS()\n",
    "model3 = AutoARIMA(start_p=2, max_p=12, start_q=1)\n",
    "model4 = RandomForest(lags=24, n_estimators=300)\n",
    "model5 = Prophet()\n",
    "\n",
    "models = {\n",
    "    #\"Theta\": model0,\n",
    "    \"Linear\": model1,\n",
    "    \"Exponential\": model2,\n",
    "    \"ARIMA\": model3,\n",
    "    \"RandomForest\": model4,\n",
    "    \"Prophet\": model5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []\n",
    "mse_list = []\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (name, model) in tqdm(enumerate(models.items()), desc=\"Progress\"):\n",
    "  print(name)\n",
    "  model.fit(series=train)\n",
    "  predictions = model.predict(n = len(test))\n",
    "  mae_score = round(mae(test, predictions), 5)\n",
    "  mae_list.append([mae_score, name])\n",
    "  mse_score = round(mse(test, predictions), 5)\n",
    "  mse_list.append([mse_score, name])\n",
    "  # mae_score = mae(test, predictions)\n",
    "  # mse_score = mse(test, predictions)\n",
    "\n",
    "  fig.add_subplot(2, 3, i+1)\n",
    "  train.plot(label=\"train\"); test.plot(label=\"test\"); predictions.plot(label=name)\n",
    "  plt.title(f\"Method: {name} (std)\"); plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig('w_o.png')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "  print(name)\n",
    "  model.fit(series=train_w[4376:])\n",
    "  predictions = model.predict(n = len(test))\n",
    "  mae_score = round(mae(test, predictions), 5)\n",
    "  mae_list.append([mae_score, name])\n",
    "  mse_score = round(mse(test, predictions), 5)\n",
    "  mse_list.append([mse_score, name])\n",
    "  # mae_score = mae(test, predictions)\n",
    "  # mse_score = mse(test, predictions)\n",
    "\n",
    "  fig.add_subplot(2, 3, i+1)\n",
    "  train_w.plot(label=\"train\"); test.plot(label=\"test\"); predictions.plot(label=name)\n",
    "  plt.title(f\"Method: {name} with sample selection\"); plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig('w.png')\n",
    "plt.show()\n",
    "\n",
    "print(mae_list)\n",
    "print(mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = NBEATSModel(\n",
    "    input_chunk_length = 24,\n",
    "    output_chunk_length= 4,\n",
    "    num_stacks = 3,\n",
    "    num_blocks = 1,\n",
    "    num_layers = 2,\n",
    "    layer_widths = 32,\n",
    "    n_epochs = 50,\n",
    "    batch_size = 12,\n",
    "    #pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1}\n",
    ")\n",
    "\n",
    "model7 = NLinearModel(\n",
    "    input_chunk_length=24,\n",
    "    output_chunk_length=4,\n",
    "    n_epochs=50,\n",
    "    #pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1}\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"NBEATS\": model6,\n",
    "    \"NLinear\": model7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []\n",
    "mse_list = []\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "  print(name)\n",
    "  model.fit(series=train)\n",
    "  predictions = model.predict(n = len(test))\n",
    "  mae_score = round(mae(test, predictions), 5)\n",
    "  mae_list.append([mae_score, name])\n",
    "  mse_score = round(mse(test, predictions), 5)\n",
    "  mse_list.append([mse_score, name])\n",
    "  # mae_score = mae(test, predictions)\n",
    "  # mse_score = mse(test, predictions)\n",
    "\n",
    "  fig.add_subplot(1, 2, i+1)\n",
    "  train.plot(label=\"train\"); test.plot(label=\"test\"); predictions.plot(label=name)\n",
    "  plt.title(f\"Method: {name}, MAE: {mae_score}, MSE: {mse_score} without sample selection\"); plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig('nn_wo.png')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "  print(name)\n",
    "  model.fit(series=train[4375:])\n",
    "  predictions = model.predict(n = len(test))\n",
    "  mae_score = round(mae(test, predictions), 5)\n",
    "  mae_list.append([mae_score, name])\n",
    "  mse_score = round(mse(test, predictions), 5)\n",
    "  mse_list.append([mse_score, name])\n",
    "\n",
    "  fig.add_subplot(1, 2, i+1)\n",
    "  train.plot(label=\"train\"); test.plot(label=\"test\"); predictions.plot(label=name)\n",
    "  plt.title(f\"Method: {name}, MAE: {mae_score}, MSE: {mse_score} with sample selection\"); plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig('nn_w.png')\n",
    "plt.show()\n",
    "\n",
    "print(mae_list)\n",
    "print(mse_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wav_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
